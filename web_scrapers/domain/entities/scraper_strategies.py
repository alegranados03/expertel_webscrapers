import logging
import os
import uuid
import zipfile
from abc import ABC, abstractmethod
from datetime import datetime
from typing import Any, Dict, List, Optional

from web_scrapers.domain.entities.browser_wrapper import BrowserWrapper
from web_scrapers.domain.entities.models import (
    BillingCycle,
    BillingCycleDailyUsageFile,
    BillingCycleFile,
    FileDownloadInfo,
    FileMappingInfo,
    ScraperConfig,
)
from web_scrapers.domain.entities.session import Credentials
from web_scrapers.infrastructure.services.file_upload_service import FileUploadService


class ScraperResult:
    def __init__(
        self,
        success: bool,
        message: str = "",
        files: Optional[List[FileMappingInfo]] = None,
        error: Optional[str] = None,
    ):
        self.success = success
        self.message = message
        self.files = files or []
        self.error = error
        self.timestamp = datetime.now()


class ScraperBaseStrategy(ABC):
    def __init__(self, browser_wrapper: BrowserWrapper):
        self.browser_wrapper = browser_wrapper
        self.logger = logging.getLogger(self.__class__.__name__)

    @abstractmethod
    def execute(self, config: ScraperConfig, billing_cycle: BillingCycle, credentials: Credentials) -> ScraperResult:
        raise NotImplementedError()

    def _create_file_mapping(self, downloaded_files: List[FileDownloadInfo]) -> List[FileMappingInfo]:
        """Convert FileDownloadInfo to mapping format required for endpoints."""
        return [
            FileMappingInfo(
                file_id=file_info.file_id,
                file_name=file_info.file_name,
                file_path=file_info.file_path,
                download_url=file_info.download_url,
                billing_cycle_file_id=file_info.billing_cycle_file.id if file_info.billing_cycle_file else None,
                carrier_report_name=(
                    file_info.billing_cycle_file.carrier_report.name
                    if (file_info.billing_cycle_file and file_info.billing_cycle_file.carrier_report)
                    else None
                ),
                daily_usage_file_id=file_info.daily_usage_file.id if file_info.daily_usage_file else None,
                pdf_file_id=file_info.pdf_file.id if file_info.pdf_file else None,
            )
            for file_info in downloaded_files
        ]

    def _extract_zip_files(self, zip_file_path: str, extract_to_dir: Optional[str] = None) -> List[str]:
        """
        Extract files from a ZIP and return paths of all extracted files.

        Args:
            zip_file_path: Path of the ZIP file to extract
            extract_to_dir: Directory to extract to (if not specified, uses ZIP directory)

        Returns:
            List of extracted file paths
        """
        extracted_files = []
        try:
            # Verify that file exists and is a ZIP
            if not os.path.exists(zip_file_path):
                self.logger.error(f"ZIP file not found: {zip_file_path}")
                return extracted_files

            if not zipfile.is_zipfile(zip_file_path):
                self.logger.error(f"File is not a valid ZIP: {zip_file_path}")
                return extracted_files

            # Determine extraction directory with unique UUID
            if extract_to_dir is None:
                zip_basename = os.path.splitext(os.path.basename(zip_file_path))[0]
                unique_id = str(uuid.uuid4())[:8]  # Use only first 8 characters of UUID
                extract_to_dir = os.path.join(os.path.dirname(zip_file_path), f"{zip_basename}_extracted_{unique_id}")

            # Create extraction directory if it doesn't exist
            os.makedirs(extract_to_dir, exist_ok=True)

            self.logger.info(f"Extracting ZIP: {os.path.basename(zip_file_path)}")
            self.logger.info(f"Extraction directory: {extract_to_dir}")

            # Extract files
            with zipfile.ZipFile(zip_file_path, "r") as zip_ref:
                file_list = zip_ref.namelist()
                self.logger.info(f"Elements in ZIP: {len(file_list)}")

                for file_name in file_list:
                    # Only process files, not directories
                    if not file_name.endswith("/"):
                        # Get only the filename (without folder path)
                        base_filename = os.path.basename(file_name)

                        # Avoid hidden or system files
                        if base_filename and not base_filename.startswith("."):
                            # Read file content from ZIP
                            file_content = zip_ref.read(file_name)

                            # Create destination path at first level
                            flattened_file_path = os.path.join(extract_to_dir, base_filename)

                            # If file with same name exists, add a number
                            counter = 1
                            original_path = flattened_file_path
                            while os.path.exists(flattened_file_path):
                                name, ext = os.path.splitext(base_filename)
                                flattened_file_path = os.path.join(extract_to_dir, f"{name}_{counter}{ext}")
                                counter += 1

                            # Write file to extraction directory (first level)
                            with open(flattened_file_path, "wb") as output_file:
                                output_file.write(file_content)

                            extracted_files.append(flattened_file_path)

                            # Show extraction information
                            if file_name != base_filename:
                                self.logger.debug(f"Extracted: {file_name} -> {base_filename}")
                            else:
                                self.logger.debug(f"Extracted: {base_filename}")
                        else:
                            self.logger.debug(f"Ignored system file: {file_name}")
                    else:
                        self.logger.debug(f"Ignored directory: {file_name}")

            # Extraction summary
            self.logger.info(f"EXTRACTION SUMMARY:")
            self.logger.info(f"Total files extracted: {len(extracted_files)}")

            if len(extracted_files) == 1:
                self.logger.info(f"Single file: {os.path.basename(extracted_files[0])}")
            else:
                self.logger.info(f"Multiple files:")
                for i, file_path in enumerate(extracted_files, 1):
                    self.logger.debug(f"     [{i}] {os.path.basename(file_path)}")

            self.logger.info("===============================")

            return extracted_files

        except Exception as e:
            self.logger.error(f"Error extracting ZIP: {str(e)}")
            return extracted_files

    def _upload_files_to_endpoint(
        self, files: List[FileDownloadInfo], config: ScraperConfig, billing_cycle: BillingCycle
    ) -> bool:
        """Base method to send files to endpoint. Override if you need specific logic."""
        try:
            upload_service = FileUploadService()

            # Determine upload type based on class
            upload_type = self._get_upload_type()

            return upload_service.upload_files_batch(
                files=files, billing_cycle=billing_cycle, upload_type=upload_type, additional_data=None
            )

        except Exception as e:
            self.logger.error(f"Error uploading files: {str(e)}")
            return False

    def _upload_files_with_individual_tracking(
        self, files: List[FileDownloadInfo], config: ScraperConfig, billing_cycle: BillingCycle
    ) -> Dict[str, Any]:
        """
        Upload files with individual tracking for each file.

        Returns a dictionary with detailed results:
        {
            'total_files': int,
            'successful_uploads': int,
            'failed_uploads': int,
            'success': bool,
            'uploaded_files': List[FileDownloadInfo],
            'failed_files': List[Dict[str, Any]]
        }
        """
        upload_service = FileUploadService()
        upload_type = self._get_upload_type()

        uploaded_files = []
        failed_files = []

        self.logger.info(f"Starting individual upload tracking for {len(files)} files...")

        for file_info in files:
            try:
                # Verify file exists and has a physical path
                if not file_info.file_path or not os.path.exists(file_info.file_path):
                    self.logger.warning(f"File not found on disk: {file_info.file_name}")
                    failed_files.append({
                        'file': file_info,
                        'reason': 'File not found on disk',
                        'file_path': file_info.file_path
                    })
                    continue

                # Attempt to upload this single file
                self.logger.info(f"Uploading: {file_info.file_name}")
                success = upload_service.upload_files_batch(
                    files=[file_info],
                    billing_cycle=billing_cycle,
                    upload_type=upload_type,
                    additional_data=None
                )

                if success:
                    self.logger.info(f"Upload successful: {file_info.file_name}")
                    uploaded_files.append(file_info)
                else:
                    self.logger.error(f"Upload failed: {file_info.file_name}")
                    failed_files.append({
                        'file': file_info,
                        'reason': 'Upload service returned failure',
                        'file_path': file_info.file_path
                    })

            except Exception as e:
                self.logger.error(f"Exception uploading {file_info.file_name}: {str(e)}")
                failed_files.append({
                    'file': file_info,
                    'reason': f'Exception: {str(e)}',
                    'file_path': file_info.file_path
                })

        # Build result summary
        result = {
            'total_files': len(files),
            'successful_uploads': len(uploaded_files),
            'failed_uploads': len(failed_files),
            'success': len(failed_files) == 0,  # Only success if ALL uploaded
            'uploaded_files': uploaded_files,
            'failed_files': failed_files
        }

        # Log summary
        self.logger.info(f"Upload tracking complete: {result['successful_uploads']}/{result['total_files']} successful")

        return result

    def _get_upload_type(self) -> str:
        """Determine upload type based on strategy class."""
        class_name = self.__class__.__name__.lower()
        if "monthly" in class_name:
            return "monthly"
        elif "daily" in class_name:
            return "daily_usage"
        elif "pdf" in class_name:
            return "pdf_invoice"
        else:
            return "unknown"


class MonthlyReportsScraperStrategy(ScraperBaseStrategy):

    def execute(self, config: ScraperConfig, billing_cycle: BillingCycle, credentials: Credentials) -> ScraperResult:
        try:
            # Step 1: Find files section
            files_section = self._find_files_section(config, billing_cycle)
            if not files_section:
                return ScraperResult(False, error="Could not find files section")

            # Step 2: Download files
            downloaded_files = self._download_files(files_section, config, billing_cycle)

            # Calculate expected files from billing_cycle
            expected_files_count = len(billing_cycle.billing_cycle_files) if billing_cycle.billing_cycle_files else 0
            downloaded_count = len(downloaded_files)

            self.logger.info(f"Download phase complete: {downloaded_count}/{expected_files_count} files downloaded")

            # Step 3: Upload files with individual tracking
            upload_tracking = self._upload_files_with_individual_tracking(downloaded_files, config, billing_cycle)

            # Step 4: Determine final success based on download and upload results
            download_failures = expected_files_count - downloaded_count
            upload_failures = upload_tracking['failed_uploads']
            total_failures = download_failures + upload_failures

            # Build detailed result message
            if total_failures == 0:
                # Perfect success: all files downloaded and uploaded
                message = f"SUCCESS: All {expected_files_count} files downloaded and uploaded"
                self.logger.info(message)
                return ScraperResult(
                    True,
                    message,
                    self._create_file_mapping(upload_tracking['uploaded_files'])
                )
            else:
                # Partial or complete failure
                error_parts = []

                if download_failures > 0:
                    error_parts.append(f"{download_failures} file(s) failed to download")

                if upload_failures > 0:
                    error_parts.append(f"{upload_failures} file(s) failed to upload")
                    # Log details of failed uploads
                    for failed in upload_tracking['failed_files']:
                        self.logger.error(
                            f"Upload failure: {failed['file'].file_name} - {failed['reason']}"
                        )

                error_message = f"ERROR: {', '.join(error_parts)}. "
                error_message += f"Expected: {expected_files_count}, "
                error_message += f"Downloaded: {downloaded_count}, "
                error_message += f"Uploaded: {upload_tracking['successful_uploads']}"

                self.logger.error(error_message)

                # Return failure with partial results
                return ScraperResult(
                    False,
                    error_message,
                    self._create_file_mapping(upload_tracking['uploaded_files']),
                    error=error_message
                )

        except Exception as e:
            self.logger.error(f"Exception in execute(): {str(e)}")
            return ScraperResult(False, error=str(e))

    @abstractmethod
    def _find_files_section(self, config: ScraperConfig, billing_cycle: BillingCycle) -> Optional[Any]:
        raise NotImplementedError()

    @abstractmethod
    def _download_files(
        self, files_section: Any, config: ScraperConfig, billing_cycle: BillingCycle
    ) -> List[FileDownloadInfo]:
        raise NotImplementedError()


class DailyUsageScraperStrategy(ScraperBaseStrategy):

    def execute(self, config: ScraperConfig, billing_cycle: BillingCycle, credentials: Credentials) -> ScraperResult:
        try:
            files_section = self._find_files_section(config, billing_cycle)
            if not files_section:
                return ScraperResult(False, error="Could not find files section")

            downloaded_files = self._download_files(files_section, config, billing_cycle)
            if not downloaded_files:
                return ScraperResult(False, error="Could not download files")

            upload_result = self._upload_files_to_endpoint(downloaded_files, config, billing_cycle)
            if not upload_result:
                return ScraperResult(False, error="Error sending files to external endpoint")

            return ScraperResult(
                True, f"Processed {len(downloaded_files)} files", self._create_file_mapping(downloaded_files)
            )

        except Exception as e:
            return ScraperResult(False, error=str(e))

    @abstractmethod
    def _find_files_section(self, config: ScraperConfig, billing_cycle: BillingCycle) -> Optional[Any]:
        raise NotImplementedError()

    @abstractmethod
    def _download_files(
        self, files_section: Any, config: ScraperConfig, billing_cycle: BillingCycle
    ) -> List[FileDownloadInfo]:
        raise NotImplementedError()


class PDFInvoiceScraperStrategy(ScraperBaseStrategy):

    def execute(self, config: ScraperConfig, billing_cycle: BillingCycle, credentials: Credentials) -> ScraperResult:
        try:
            files_section = self._find_files_section(config, billing_cycle)
            if not files_section:
                return ScraperResult(False, error="Could not find files section")

            downloaded_files = self._download_files(files_section, config, billing_cycle)
            if not downloaded_files:
                return ScraperResult(False, error="Could not download files")

            upload_result = self._upload_files_to_endpoint(downloaded_files, config, billing_cycle)
            if not upload_result:
                return ScraperResult(False, error="Error sending files to external endpoint")

            return ScraperResult(
                True, f"Processed {len(downloaded_files)} files", self._create_file_mapping(downloaded_files)
            )

        except Exception as e:
            return ScraperResult(False, error=str(e))

    @abstractmethod
    def _find_files_section(self, config: ScraperConfig, billing_cycle: BillingCycle) -> Optional[Any]:
        raise NotImplementedError()

    @abstractmethod
    def _download_files(
        self, files_section: Any, config: ScraperConfig, billing_cycle: BillingCycle
    ) -> List[FileDownloadInfo]:
        raise NotImplementedError()
